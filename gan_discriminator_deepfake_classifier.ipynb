{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ochoa-josue/techwise-deepfake-classification/blob/feature%2Fgan-model/gan_discriminator_deepfake_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQOv309EpBkn"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet tensorflow matplotlib tensorflow-datasets ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HkbfG52pMPq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory #load image datasets\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.models import Sequential, load_model #sequential api for generator and discriminator\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.metrics import AUC #area under the curve for model performance (especially imbalanced datasets)\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pma4qS78nxM",
        "outputId": "305a2cc2-abb0-48ca-f88b-46a0433c6951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWfFq3ojsVyn"
      },
      "source": [
        "### **Retrieve and Preprocess Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNGHH8DHpaWi",
        "outputId": "f63d8ab5-f224-4103-9e05-6b58bb5ba8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracted files: ['valid', 'test', 'train']\n",
            "['valid', 'test', 'train']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "# os.chdir(\"/content/drive/My Drive/conforming-images-subset\") #change current working directory to specified directory\n",
        "\n",
        "zip_file_path = '/content/drive/My Drive/conforming_images_subset.zip'\n",
        "extracted_dir_path = '/content/conforming-images-subset/'\n",
        "os.makedirs(extracted_dir_path, exist_ok=True) #creates dir if non-existent\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extracted_dir_path)\n",
        "\n",
        "extracted_files = os.listdir(extracted_dir_path)\n",
        "print(f\"extracted files: {extracted_files}\")\n",
        "print(extracted_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M938AyIzqbP5"
      },
      "outputs": [],
      "source": [
        "# train_dir = \"/content/drive/My Drive/conforming-images-subset/train\"\n",
        "# valid_dir = \"/content/drive/My Drive/conforming-images-subset/valid\"\n",
        "# test_dir = \"/content/drive/My Drive/conforming-images-subset/test\"\n",
        "\n",
        "train_dir = os.path.join(extracted_dir_path, 'train')\n",
        "valid_dir = os.path.join(extracted_dir_path, 'valid')\n",
        "test_dir = os.path.join(extracted_dir_path, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-dUuF9ptZnm"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.05),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.05),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.05, width_factor=0.05),\n",
        "])\n",
        "\n",
        "def preprocess(images, labels):\n",
        "  images = tf.cast(images, tf.float32) #convert tensor img to tf.float32 type\n",
        "  images = images / 255.0 #normalize data between 0 to 1\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "def preprocess_with_augmentation(images, labels):\n",
        "  images = data_augmentation(images, training=True)\n",
        "  images = tf.cast(images, tf.float32) #convert tensor img to tf.float32 type\n",
        "  images = images / 255.0 #normalize data between range 0 to 1\n",
        "  return images, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLbtXDiayObL",
        "outputId": "59b1c731-250b-4760-86f5-f2213f3991d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = image_dataset_from_directory(train_dir, label_mode='binary', image_size=(256,256), batch_size=32) #image anomaly detection\n",
        "valid_dataset = image_dataset_from_directory(valid_dir, label_mode='binary', image_size=(256,256), batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(test_dir, label_mode='binary', image_size=(256,256), batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCjfn1vysSC2"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(preprocess_with_augmentation)\n",
        "valid_dataset = valid_dataset.map(preprocess)\n",
        "test_dataset = test_dataset.map(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eBUHqtV6Qe1"
      },
      "source": [
        "### **Build GAN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2qn1BlwvEay"
      },
      "outputs": [],
      "source": [
        "class GAN(tf.keras.Model):\n",
        "  def __init__(self, generator, discriminator):\n",
        "    super(GAN, self).__init__() #invoking constructor of tf.keras.Model to initialize GAN proxy object\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "\n",
        "  def compile(self, g_optimizer, d_optimizer, loss_function):\n",
        "    super(GAN, self).compile() #ensure compilation of parent class is executed\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.loss_function = loss_function\n",
        "\n",
        "  def train_step(self, real_images): #override parent train_step when calling to TensorFlow fit function\n",
        "    batch_size = tf.shape(real_images)[0] #retrieving batch size\n",
        "    noise_dim = 128 #128 dimensions\n",
        "\n",
        "    #generate fake images\n",
        "    random_noise = tf.random.normal(shape=(batch_size, noise_dim)) #create random noise vectors with Gaussian distribution\n",
        "    fake_images = self.generator(random_noise, training=True)\n",
        "\n",
        "    #train discriminator\n",
        "    with tf.GradientTape() as disc_tape: #records operations on tensors; thereafter performs automatic differentiation, in other words, compute derivatives or gradients of functions\n",
        "        real_output = self.discriminator(real_images, training=True)\n",
        "        fake_output = self.discriminator(fake_images, training=True)\n",
        "\n",
        "        #calculate loss\n",
        "        real_loss = self.loss_function(tf.ones_like(real_output), real_output)\n",
        "        fake_loss = self.loss_function(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "        #total discriminator loss\n",
        "        disc_loss = real_loss + fake_loss\n",
        "\n",
        "    #calculate gradients for discriminator\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "    #apply gradients to the optimizer\n",
        "    self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
        "\n",
        "    #train generator\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      fake_images = self.generator(random_noise, training=True) #generate fake images\n",
        "      fake_output = self.discriminator(fake_images, training=True) #disc predict fake images\n",
        "      gen_loss = self.loss_function(tf.ones_like(fake_output), fake_output) #show generator loss; maximimize loss to optimize generator\n",
        "\n",
        "    #calculate gradients for generator\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "    #apply gradients to the optimizer\n",
        "    self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
        "\n",
        "    return {'disc_loss': disc_loss, 'gen_loss': gen_loss}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdePdiVH6sul"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(7*7*128, input_dim=128)) #intakes 128-dimesional input of random noise to output tensor shape\n",
        "  model.add(LeakyReLU(0.2)) #introduce non-linearlity for continued learning\n",
        "  model.add(BatchNormalization(momentum=0.8)) #stabilize training process by tracking moving averages overtime; faster convergence\n",
        "  model.add(Reshape((7, 7, 128))) #reshapes into 4D tensor which inclues batch size, height, width, and channels\n",
        "\n",
        "  #upsampling block 1\n",
        "  model.add(UpSampling2D()) #double dimensions of the input tensor for higher resolutions from low-dimensional noise vectors\n",
        "  model.add(Conv2D(128, 5, padding='same')) #adds a convolutional layer with 256 filters, 5x5 kernel size, and same padding to preserve spatial dimensions as input image\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "  #upsampling block 2\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(64, 5, padding='same')) #reduce filters to prevent overfitting and allow feature abstraction e.g. capturing simple patterns (edges, textures)\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "  #simplify model\n",
        "  #convolution block 1\n",
        "  model.add(Conv2D(128, 4, padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  #output layer adjustment; output layer is tanh activation\n",
        "  model.add(Conv2D(3, 4, padding='same', activation='sigmoid')) #sigmoid activation for data normalized between 0 and 1 for RGB images\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y53-_E657oGG"
      },
      "outputs": [],
      "source": [
        "def build_discriminator(input_shape=(256, 256, 3)):\n",
        "  model = Sequential([\n",
        "      #convolution block 1\n",
        "      Conv2D(32, kernel_size=5, strides=2, input_shape=input_shape, padding=\"same\", kernel_regularizer=l2(0.01)), #stride reduces spatial dimensions by half\n",
        "      LeakyReLU(alpha=0.2),\n",
        "      Dropout(0.3), #prevent overfitting where 30% of input units or features are randomly set to zero\n",
        "\n",
        "      #convolution block 2\n",
        "      Conv2D(64, kernel_size=5, strides=2, padding=\"same\", kernel_regularizer=l2(0.01)),\n",
        "      LeakyReLU(alpha=0.2),\n",
        "      Dropout(0.3),\n",
        "\n",
        "      #simplify model\n",
        "      #convolution block 3\n",
        "      Conv2D(256, kernel_size=5, strides=2, padding=\"same\"),\n",
        "      LeakyReLU(alpha=0.2),\n",
        "      Dropout(0.3),\n",
        "\n",
        "      #flatten and output layer\n",
        "      Flatten(), #flatten into a 1D tensor for easier integration with fully connected layers\n",
        "      Dense(1, kernel_regularizer=l2(0.01)) #indicate whether image is real or fake\n",
        "  ])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf9CmNVbvyyW"
      },
      "source": [
        "### **Data Visualization and Compiling GAN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7rUHL8N6Sj9"
      },
      "outputs": [],
      "source": [
        "# generator = build_generator()\n",
        "# g_optimizer = tf.keras.optimizers.Adam(1e-4) #find best convergence along with optimal learning rate\n",
        "# noise_dim = 128\n",
        "# gan_model = GAN(generator, discriminator, noise_dim) #create GAN\n",
        "# gan_model.compile(g_optimizer=g_optimizer, d_optimizer=d_optimizer) #compile GAN\n",
        "# gan_model.fit(train_dataset, epochs=50, validation_data=valid_dataset, callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "d_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "discriminator.compile(optimizer=d_optimizer, loss=loss_function, metrics=['accuracy', AUC(name='auc')])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def check_and_remount_drive():\n",
        "#   drive_mount_point = '/content/drive'\n",
        "#   drive_base_path = '/content/drive/My Drive'\n",
        "\n",
        "#   if not os.path.isdir(drive_base_path): #look for base path to ensure drive mounted\n",
        "#     print('Mounting Google Drive')\n",
        "#     drive.mount(drive_mount_point, force_remount=True)\n",
        "#     print(\"Mounted Google Drive successfully\")"
      ],
      "metadata": {
        "id": "rItAOyDeqOgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from google.colab import output\n",
        "import time\n",
        "import json\n",
        "\n",
        "model_dir = '/content/drive/My Drive/models'\n",
        "log_dir = '/content/drive/My Drive/logs'\n",
        "state_file = os.path.join(model_dir, 'training_state.json')\n",
        "\n",
        "#if dir non-existent\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_file_path = os.path.join(log_dir, f\"training_{current_time}.log.txt\")\n",
        "logging.basicConfig(filename=log_file_path, level=logging.INFO, format='%(asctime)s %(message)s')"
      ],
      "metadata": {
        "id": "UNNA2uCLmajy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_cb = ModelCheckpoint(os.path.join(model_dir, \"ckpt_epoch_{epoch:02d}.h5\"), save_freq='epoch', verbose=1) #display progress bar during saving\n",
        "# checkpoint_cb = ModelCheckpoint(\"/content/drive/My Drive/models/best_discriminator.h5\", save_best_only=True, monitor='val_loss') #callback to save the best model checkpoint during training\n",
        "early_stopping_cb = EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss') #stop training if no improvement at 15 consecutive epochs\n",
        "# tensorboard_cb = TensorBoard(log_dir='/content/drive/My Drive/logs', histogram_freq=1) #TensorBoard callback to visualize model performance\n",
        "tensorboard_cb = TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "M_Q3DVvQeO0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_training_state(epoch, accuracy):\n",
        "  state = {'last_epoch': epoch, 'last_accuracy': accuracy}\n",
        "  with open(state_file, 'w') as f:\n",
        "    json.dump(state, f) #serialize Python objects into JSON formatted str\n",
        "\n",
        "def load_training_state():\n",
        "  if os.path.exists(state_file):\n",
        "    print(f\"Found training state file: {state_file}\")\n",
        "    with open(state_file) as f:\n",
        "      return json.load(f)\n",
        "  else:\n",
        "    print(f\"No training state file found at {state_file}. Creating a new one.\")\n",
        "    save_training_state(0, 0.0)\n",
        "    return {'last_epoch': 0, 'last_accuracy': 0}\n",
        "\n",
        "class SaveStateCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    save_training_state(epoch + 1, logs.get('accuracy', 0.0))\n",
        "\n",
        "state = load_training_state()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RU1w-9OXK8F",
        "outputId": "4dc148fb-5acf-48d9-83f2-19036f3f7c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found training state file: /content/drive/My Drive/models/training_state.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_files = [f for f in os.listdir(model_dir) if 'ckpt_epoch_' in f and f.endswith('.h5')] #find latest checkpoint file\n",
        "latest_epoch = state['last_epoch']\n",
        "latest_accuracy = state['last_accuracy']\n",
        "\n",
        "if checkpoint_files: #find max checkpoint\n",
        "    epochs = [int(re.search(r'ckpt_epoch_(\\d+).h5', f).group(1)) for f in checkpoint_files]\n",
        "    latest_epoch = max(epochs)\n",
        "    latest_checkpoint = f'ckpt_epoch_{latest_epoch}.h5'\n",
        "    checkpoint_path = os.path.join(model_dir, latest_checkpoint)\n",
        "\n",
        "    print(f\"Loading weights from {checkpoint_path}\")\n",
        "    discriminator.load_weights(checkpoint_path)\n",
        "    print(f\"Resuming training from epoch {latest_epoch + 1} with last accuracy {latest_accuracy}\")\n",
        "else:\n",
        "    print(\"No checkpoint files found. Starting or continuing from the last known state.\")\n",
        "\n",
        "initial_epoch = latest_epoch\n",
        "total_epochs = 100\n",
        "\n",
        "save_state_cb = SaveStateCallback()\n",
        "\n",
        "history = discriminator.fit(train_dataset, epochs=total_epochs, validation_data=valid_dataset,\n",
        "                  callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb, save_state_cb],\n",
        "                  initial_epoch=initial_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB9PN0zzmjy0",
        "outputId": "60da221c-7bc2-4958-b067-b74d4fef5458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from /content/drive/My Drive/models/ckpt_epoch_21.h5\n",
            "Resuming training from epoch 22 with last accuracy 0.0\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6195 - accuracy: 0.6704 - auc: 0.7310\n",
            "Epoch 22: saving model to /content/drive/My Drive/models/ckpt_epoch_22.h5\n",
            "625/625 [==============================] - 3102s 5s/step - loss: 0.6195 - accuracy: 0.6704 - auc: 0.7310 - val_loss: 0.5960 - val_accuracy: 0.6842 - val_auc: 0.7412\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.6728 - auc: 0.7273\n",
            "Epoch 23: saving model to /content/drive/My Drive/models/ckpt_epoch_23.h5\n",
            "625/625 [==============================] - 3037s 5s/step - loss: 0.6198 - accuracy: 0.6728 - auc: 0.7273 - val_loss: 0.5942 - val_accuracy: 0.6805 - val_auc: 0.7301\n",
            "Epoch 24/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.6763 - auc: 0.7326\n",
            "Epoch 24: saving model to /content/drive/My Drive/models/ckpt_epoch_24.h5\n",
            "625/625 [==============================] - 3043s 5s/step - loss: 0.6147 - accuracy: 0.6763 - auc: 0.7326 - val_loss: 0.5988 - val_accuracy: 0.6718 - val_auc: 0.7350\n",
            "Epoch 25/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.6777 - auc: 0.7324\n",
            "Epoch 25: saving model to /content/drive/My Drive/models/ckpt_epoch_25.h5\n",
            "625/625 [==============================] - 3008s 5s/step - loss: 0.6159 - accuracy: 0.6777 - auc: 0.7324 - val_loss: 0.6097 - val_accuracy: 0.6555 - val_auc: 0.7180\n",
            "Epoch 26/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6181 - accuracy: 0.6747 - auc: 0.7304\n",
            "Epoch 26: saving model to /content/drive/My Drive/models/ckpt_epoch_26.h5\n",
            "625/625 [==============================] - 3002s 5s/step - loss: 0.6181 - accuracy: 0.6747 - auc: 0.7304 - val_loss: 0.5976 - val_accuracy: 0.6727 - val_auc: 0.7364\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6151 - accuracy: 0.6795 - auc: 0.7360\n",
            "Epoch 27: saving model to /content/drive/My Drive/models/ckpt_epoch_27.h5\n",
            "625/625 [==============================] - 2998s 5s/step - loss: 0.6151 - accuracy: 0.6795 - auc: 0.7360 - val_loss: 0.5939 - val_accuracy: 0.6747 - val_auc: 0.7374\n",
            "Epoch 28/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.6783 - auc: 0.7353\n",
            "Epoch 28: saving model to /content/drive/My Drive/models/ckpt_epoch_28.h5\n",
            "625/625 [==============================] - 3012s 5s/step - loss: 0.6135 - accuracy: 0.6783 - auc: 0.7353 - val_loss: 0.6048 - val_accuracy: 0.7103 - val_auc: 0.7645\n",
            "Epoch 29/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6122 - accuracy: 0.6840 - auc: 0.7386\n",
            "Epoch 29: saving model to /content/drive/My Drive/models/ckpt_epoch_29.h5\n",
            "625/625 [==============================] - 3023s 5s/step - loss: 0.6122 - accuracy: 0.6840 - auc: 0.7386 - val_loss: 0.5970 - val_accuracy: 0.7255 - val_auc: 0.7857\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.6837 - auc: 0.7381\n",
            "Epoch 30: saving model to /content/drive/My Drive/models/ckpt_epoch_30.h5\n",
            "625/625 [==============================] - 3006s 5s/step - loss: 0.6106 - accuracy: 0.6837 - auc: 0.7381 - val_loss: 0.5902 - val_accuracy: 0.6770 - val_auc: 0.7423\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6074 - accuracy: 0.6874 - auc: 0.7438\n",
            "Epoch 31: saving model to /content/drive/My Drive/models/ckpt_epoch_31.h5\n",
            "625/625 [==============================] - 3000s 5s/step - loss: 0.6074 - accuracy: 0.6874 - auc: 0.7438 - val_loss: 0.5936 - val_accuracy: 0.7017 - val_auc: 0.7505\n",
            "Epoch 32/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6092 - accuracy: 0.6877 - auc: 0.7407\n",
            "Epoch 32: saving model to /content/drive/My Drive/models/ckpt_epoch_32.h5\n",
            "625/625 [==============================] - 2964s 5s/step - loss: 0.6092 - accuracy: 0.6877 - auc: 0.7407 - val_loss: 0.6020 - val_accuracy: 0.6665 - val_auc: 0.7278\n",
            "Epoch 33/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6063 - accuracy: 0.6914 - auc: 0.7450\n",
            "Epoch 33: saving model to /content/drive/My Drive/models/ckpt_epoch_33.h5\n",
            "625/625 [==============================] - 2963s 5s/step - loss: 0.6063 - accuracy: 0.6914 - auc: 0.7450 - val_loss: 0.5982 - val_accuracy: 0.6808 - val_auc: 0.7324\n",
            "Epoch 34/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6062 - accuracy: 0.6921 - auc: 0.7454\n",
            "Epoch 34: saving model to /content/drive/My Drive/models/ckpt_epoch_34.h5\n",
            "625/625 [==============================] - 2958s 5s/step - loss: 0.6062 - accuracy: 0.6921 - auc: 0.7454 - val_loss: 0.6070 - val_accuracy: 0.6550 - val_auc: 0.7178\n",
            "Epoch 35/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.6928 - auc: 0.7466\n",
            "Epoch 35: saving model to /content/drive/My Drive/models/ckpt_epoch_35.h5\n",
            "625/625 [==============================] - 2979s 5s/step - loss: 0.6050 - accuracy: 0.6928 - auc: 0.7466 - val_loss: 0.5899 - val_accuracy: 0.6850 - val_auc: 0.7461\n",
            "Epoch 36/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.6926 - auc: 0.7481\n",
            "Epoch 36: saving model to /content/drive/My Drive/models/ckpt_epoch_36.h5\n",
            "625/625 [==============================] - 2981s 5s/step - loss: 0.6046 - accuracy: 0.6926 - auc: 0.7481 - val_loss: 0.5816 - val_accuracy: 0.7117 - val_auc: 0.7667\n",
            "Epoch 37/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6020 - accuracy: 0.6963 - auc: 0.7535\n",
            "Epoch 37: saving model to /content/drive/My Drive/models/ckpt_epoch_37.h5\n",
            "625/625 [==============================] - 2986s 5s/step - loss: 0.6020 - accuracy: 0.6963 - auc: 0.7535 - val_loss: 0.6135 - val_accuracy: 0.6557 - val_auc: 0.7184\n",
            "Epoch 38/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5995 - accuracy: 0.7006 - auc: 0.7526\n",
            "Epoch 38: saving model to /content/drive/My Drive/models/ckpt_epoch_38.h5\n",
            "625/625 [==============================] - 2989s 5s/step - loss: 0.5995 - accuracy: 0.7006 - auc: 0.7526 - val_loss: 0.5991 - val_accuracy: 0.6740 - val_auc: 0.7349\n",
            "Epoch 39/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6012 - accuracy: 0.7001 - auc: 0.7550\n",
            "Epoch 39: saving model to /content/drive/My Drive/models/ckpt_epoch_39.h5\n",
            "625/625 [==============================] - 2989s 5s/step - loss: 0.6012 - accuracy: 0.7001 - auc: 0.7550 - val_loss: 0.5768 - val_accuracy: 0.7232 - val_auc: 0.7756\n",
            "Epoch 40/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5998 - accuracy: 0.7009 - auc: 0.7552\n",
            "Epoch 40: saving model to /content/drive/My Drive/models/ckpt_epoch_40.h5\n",
            "625/625 [==============================] - 3007s 5s/step - loss: 0.5998 - accuracy: 0.7009 - auc: 0.7552 - val_loss: 0.5914 - val_accuracy: 0.6865 - val_auc: 0.7390\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.6999 - auc: 0.7550\n",
            "Epoch 41: saving model to /content/drive/My Drive/models/ckpt_epoch_41.h5\n",
            "625/625 [==============================] - 3018s 5s/step - loss: 0.6003 - accuracy: 0.6999 - auc: 0.7550 - val_loss: 0.5945 - val_accuracy: 0.6722 - val_auc: 0.7339\n",
            "Epoch 42/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.7020 - auc: 0.7582\n",
            "Epoch 42: saving model to /content/drive/My Drive/models/ckpt_epoch_42.h5\n",
            "625/625 [==============================] - 3007s 5s/step - loss: 0.5951 - accuracy: 0.7020 - auc: 0.7582 - val_loss: 0.5756 - val_accuracy: 0.7207 - val_auc: 0.7802\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5975 - accuracy: 0.7050 - auc: 0.7575\n",
            "Epoch 43: saving model to /content/drive/My Drive/models/ckpt_epoch_43.h5\n",
            "625/625 [==============================] - 3000s 5s/step - loss: 0.5975 - accuracy: 0.7050 - auc: 0.7575 - val_loss: 0.5804 - val_accuracy: 0.6957 - val_auc: 0.7526\n",
            "Epoch 44/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5936 - accuracy: 0.7061 - auc: 0.7614\n",
            "Epoch 44: saving model to /content/drive/My Drive/models/ckpt_epoch_44.h5\n",
            "625/625 [==============================] - 3013s 5s/step - loss: 0.5936 - accuracy: 0.7061 - auc: 0.7614 - val_loss: 0.5773 - val_accuracy: 0.7035 - val_auc: 0.7557\n",
            "Epoch 45/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5933 - accuracy: 0.7073 - auc: 0.7616\n",
            "Epoch 45: saving model to /content/drive/My Drive/models/ckpt_epoch_45.h5\n",
            "625/625 [==============================] - 3020s 5s/step - loss: 0.5933 - accuracy: 0.7073 - auc: 0.7616 - val_loss: 0.5730 - val_accuracy: 0.7218 - val_auc: 0.7839\n",
            "Epoch 46/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5919 - accuracy: 0.7084 - auc: 0.7659\n",
            "Epoch 46: saving model to /content/drive/My Drive/models/ckpt_epoch_46.h5\n",
            "625/625 [==============================] - 3010s 5s/step - loss: 0.5919 - accuracy: 0.7084 - auc: 0.7659 - val_loss: 0.5699 - val_accuracy: 0.7262 - val_auc: 0.7778\n",
            "Epoch 47/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5924 - accuracy: 0.7108 - auc: 0.7648\n",
            "Epoch 47: saving model to /content/drive/My Drive/models/ckpt_epoch_47.h5\n",
            "625/625 [==============================] - 2997s 5s/step - loss: 0.5924 - accuracy: 0.7108 - auc: 0.7648 - val_loss: 0.5729 - val_accuracy: 0.7085 - val_auc: 0.7664\n",
            "Epoch 48/100\n",
            "606/625 [============================>.] - ETA: 1:26 - loss: 0.5937 - accuracy: 0.7136 - auc: 0.7629"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# state = load_training_state()\n",
        "# start_epoch = state['last_epoch']\n",
        "# total_epochs = 100\n",
        "# # epochs_per_batch = 10\n",
        "\n",
        "# output.clear()\n",
        "# print(\"training start\")\n",
        "\n",
        "# latest_checkpoint = tf.train.latest_checkpoint(model_dir)\n",
        "# if latest_checkpoint:\n",
        "#   logging.info(f\"Resuming from {latest_checkpoint}, at accuracy {state['last_accuracy']}\")\n",
        "#   discriminator.load_weights(latest_checkpoint)\n",
        "\n",
        "# save_state_cb = SaveStateCallback()\n",
        "\n",
        "# discriminator.fit(train_dataset, epochs=total_epochs, validation_data=valid_dataset, callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb], initial_epoch=start_epoch)\n",
        "\n",
        "#----\n",
        "\n",
        "# check_and_remount_drive() #ensure Drive is mounted before logging\n",
        "\n",
        "# for batch in range((start_epoch - 1) // epochs_per_batch, total_epochs // epochs_per_batch):\n",
        "#   latest_checkpoint = tf.train.latest_checkpoint(model_dir)\n",
        "#   if latest_checkpoint:\n",
        "#     logging.info(f\"Resuming from {latest_checkpoint}, at accuracy {state['last_accuracy']}\")\n",
        "#     discriminator.load_weights(latest_checkpoint)\n",
        "\n",
        "#   # start_batch_epoch = max(start_epoch - batch * epochs_per_batch, 1)\n",
        "#   # end_batch_epoch = start_batch_epoch + epochs_per_batch\n",
        "#   end_epoch = min((batch+1) * epochs_per_batch, total_epochs) #doesn't exceed total_epochs\n",
        "#   for epoch in range(start_epoch, end_epoch + 1): # add 1 to include end_epoch\n",
        "#     history = discriminator.fit(train_dataset, epochs=1, validation_data=valid_dataset, callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb], initial_epoch=epoch-1, epochs=epoch) #epoch-1 to for 0 indexing in TensorFlow\n",
        "\n",
        "#     current_accuracy = history.history['accuracy'][-1] if 'accuracy' in history.history else 0\n",
        "#     save_training_state(batch+1, epoch, current_accuracy)\n",
        "\n",
        "#     logging.info(f\"resumed at accuracy {current_accuracy}, batch {batch+1}, epoch {epoch}/{total_epochs}: loss={history.history['loss'][-1]}, accuracy={history.history['accuracy'][-1]}, val_loss={history.history['val_loss'][-1]}, val_accuracy={history.history.get('val_accuracy', [-1])[-1]}\")\n",
        "\n",
        "#     if epoch % epochs_per_batch == 0 or epoch == total_epochs:\n",
        "#       output.clear()\n",
        "\n",
        "#   start_epoch = end_epoch + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "q8HPoQStd8G3",
        "outputId": "7c7be321-b69d-4b4c-dfeb-cc33b949efc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training start\n",
            "Epoch 1/100\n",
            "  2/625 [..............................] - ETA: 48:23 - loss: 1.2264 - accuracy: 0.4688 - auc: 0.4390"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-524669807823>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msave_state_cb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveStateCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# check_and_remount_drive() #ensure Drive is mounted before logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = discriminator.evaluate(test_dataset) #evaluate model performance for unseen data\n",
        "logging.info(f\"test accuracy: {test_accuracy*100:.2f}%\")\n",
        "print(f\"test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "p-D51KsPfBFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.save('/content/drive/My Drive/final_discriminator_model.h5')"
      ],
      "metadata": {
        "id": "fo3DdywlfBuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YU2FXT3xpDyY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "#visualize AUC\n",
        "plt.plot(history.history['auc'], label='Training AUC')\n",
        "plt.plot(history.history['val_auc'], label='Validation AUC')\n",
        "plt.title('Training and Validation AUC')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize training process\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6ievPAaDk2Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model performance\n",
        "train_loss, train_accuracy = discriminator.evaluate(train_dataset)\n",
        "val_loss, val_accuracy = discriminator.evaluate(valid_dataset)\n",
        "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Training Accuracy: {val_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "EdbRVvXhk47a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions_and_labels(model, dataset):\n",
        "  predictions = []\n",
        "  true_labels = []\n",
        "\n",
        "  for images, labels in dataset:\n",
        "    preds = model.predict(images)\n",
        "    preds = (preds > 0.5).astype(np.int) #convert probabilities to binary labels\n",
        "    predictions.extend(preds.flatten())\n",
        "    true_labels.extend(labels.numpy().flatten())\n",
        "\n",
        "  return np.array(predictions), np.array(true_labels)"
      ],
      "metadata": {
        "id": "YgCya5gHk8i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, true_labels = get_predictions_and_labels(discriminator, valid_dataset)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")"
      ],
      "metadata": {
        "id": "GeFwGVuFk-d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(true_labels, predictions)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sh-XCshTlA5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_deepfake(image_path, model):\n",
        "  img = image.load_img(image_path, target_size=(256, 256))\n",
        "  img_array = image.img_to_array(img)\n",
        "  img_array = np.expand_dims(img_array, axis=0) #expand dimensions\n",
        "  img_array = img_array / 255.0 #normalize from 0 to 1\n",
        "  logits = model.predict(img_array)\n",
        "  probabilities = tf.sigmoid(logits) #convert logits to probabilities\n",
        "\n",
        "  return \"fake\" if probabilities.numpy()[0] < 0.5 else \"real\""
      ],
      "metadata": {
        "id": "0LdQTu3NktN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMQxGyETuUQR"
      },
      "outputs": [],
      "source": [
        "saved_discriminator = load_model('final_discriminator_model.h5')\n",
        "\n",
        "# example usage\n",
        "# result = predict_deepfake('image_path.jpg', saved_discriminator)\n",
        "# print(\"The image is: \", result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}