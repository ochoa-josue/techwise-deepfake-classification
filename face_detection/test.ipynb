{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mdc29sMADr1"
      },
      "source": [
        "<h2>Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XbX7kLGqADr4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGil-PvlADr5"
      },
      "source": [
        "<h2>Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H7YkWUDFADr5"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join(\"model\", \"facetracker.h5\")\n",
        "if os.path.exists(model_path):\n",
        "    model = load_model(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdRPI5XrADr5"
      },
      "source": [
        "<h2>Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeV8-OeVADr5"
      },
      "outputs": [],
      "source": [
        "def predict(img_path):\n",
        "    # Preprocessing Image\n",
        "    byte_img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "    img = tf.image.resize(img, (120,120))\n",
        "    img = img/255\n",
        "\n",
        "    # Making Prediction\n",
        "    yhat = model.predict(np.expand_dims(img, 0))\n",
        "    cls = yhat[0][0][0]\n",
        "    coords = yhat[1][0]\n",
        "    print(\"Class:\", cls)\n",
        "    print(\"Coordinates:\", coords)\n",
        "\n",
        "    # Plotting Image\n",
        "    fig, axs = plt.subplots(ncols=2, figsize=(10,10))\n",
        "    axs[0].imshow(img)\n",
        "    x1, y1, x2, y2 = coords * 120\n",
        "    width = x2 - x1\n",
        "    height = y2 - y1\n",
        "    rectangle = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor=\"r\", facecolor=\"None\")\n",
        "    axs[1].imshow(img)\n",
        "    axs[1].add_patch(rectangle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suCW-uLmADr6"
      },
      "outputs": [],
      "source": [
        "test_images_path = os.path.join(\"data\", \"test\", \"images\")\n",
        "test_images_list = os.listdir(test_images_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxdiyifpADr6"
      },
      "outputs": [],
      "source": [
        "image_name = random.choice(test_images_list)\n",
        "image_path = os.path.join(test_images_path, image_name)\n",
        "predict(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTCxudnSADr6"
      },
      "source": [
        "<h2>Live Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "mKqm8I9qADr6",
        "outputId": "23f5589a-01b7-493c-f620-532aae9bda5a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cv2' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-996d53ac2ba2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    _ , frame = cap.read()\n",
        "    frame = frame[50:500, 50:500,:]\n",
        "\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    resized = tf.image.resize(rgb, (120,120))\n",
        "\n",
        "    yhat = model.predict(np.expand_dims(resized/255,0))\n",
        "    sample_coords = yhat[1][0]\n",
        "\n",
        "    if yhat[0] > 0.5:\n",
        "        # Controls the main rectangle\n",
        "        cv2.rectangle(frame,\n",
        "                      tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)),\n",
        "                      tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)),\n",
        "                            (255,0,0), 2)\n",
        "        # Controls the label rectangle\n",
        "        cv2.rectangle(frame,\n",
        "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
        "                                    [0,-30])),\n",
        "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
        "                                    [80,0])),\n",
        "                            (255,0,0), -1)\n",
        "\n",
        "        # Controls the text rendered\n",
        "        cv2.putText(frame, 'face', tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
        "                                               [0,-5])),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
        "\n",
        "    cv2.imshow('FaceTrack', frame)\n",
        "\n",
        "    key = cv2.waitKey(1)\n",
        "\n",
        "    if key & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0PJ_tdXADr7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
